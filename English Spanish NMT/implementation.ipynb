{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Seq2SeqAttentionClass.ipynb\n",
      "importing Jupyter notebook from generators.ipynb\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "from Seq2SeqAttentionClass import Seq2SeqAttention\n",
    "import generators as gens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reservoir sampling:   9%|â–‰         | 508410/5696850 [00:03<00:37, 138394.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Guillermo\\Desktop\\My_projects\\NLP\\English Spanish NMT\\implementation.ipynb Cell 2\u001b[0m in \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guillermo/Desktop/My_projects/NLP/English%20Spanish%20NMT/implementation.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m tokenizer_data_percentage \u001b[39m=\u001b[39m \u001b[39m.05\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guillermo/Desktop/My_projects/NLP/English%20Spanish%20NMT/implementation.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m training_data_percentage \u001b[39m=\u001b[39m \u001b[39m.05\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Guillermo/Desktop/My_projects/NLP/English%20Spanish%20NMT/implementation.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data_gen \u001b[39m=\u001b[39m gens\u001b[39m.\u001b[39;49mMemoryDataGenerator(file_path, batch_size\u001b[39m=\u001b[39;49mbatch_size, max_words\u001b[39m=\u001b[39;49mmax_words,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guillermo/Desktop/My_projects/NLP/English%20Spanish%20NMT/implementation.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                      tokenizer_data_percentage \u001b[39m=\u001b[39;49m tokenizer_data_percentage,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Guillermo/Desktop/My_projects/NLP/English%20Spanish%20NMT/implementation.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                        training_data_percentage \u001b[39m=\u001b[39;49m training_data_percentage)\n",
      "File \u001b[1;32m<string>:43\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, file_path, batch_size, max_words, shuffle, tokenizer_data_percentage, training_data_percentage)\u001b[0m\n",
      "File \u001b[1;32m<string>:66\u001b[0m, in \u001b[0;36m_fit_tokenizers\u001b[1;34m(self)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Guillermo\\anaconda3\\envs\\py310\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Guillermo\\anaconda3\\envs\\py310\\lib\\codecs.py:319\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.decode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_buffer_decode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, errors, final):\n\u001b[0;32m    315\u001b[0m     \u001b[39m# Overwrite this method in subclasses: It must decode input\u001b[39;00m\n\u001b[0;32m    316\u001b[0m     \u001b[39m# and return an (output, length consumed) tuple\u001b[39;00m\n\u001b[0;32m    317\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m\n\u001b[1;32m--> 319\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m, final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    320\u001b[0m     \u001b[39m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[0;32m    321\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer \u001b[39m+\u001b[39m \u001b[39minput\u001b[39m\n\u001b[0;32m    322\u001b[0m     (result, consumed) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer_decode(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merrors, final)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "file_path = 'C:/Users/Guillermo/Desktop/My_projects/Data/english_spanish/EN-ES.txt'\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "max_words = 1000\n",
    "tokenizer_data_percentage = .05\n",
    "training_data_percentage = .05\n",
    "\n",
    "data_gen = gens.MemoryDataGenerator(file_path, batch_size=batch_size, max_words=max_words,\n",
    "                                     tokenizer_data_percentage = tokenizer_data_percentage,\n",
    "                                       training_data_percentage = training_data_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size_source = max_words\n",
    "vocab_size_target = max_words\n",
    "embedding_dim = 150\n",
    "lstm_units = 128\n",
    "\n",
    "# Initialize the model\n",
    "model = Seq2SeqAttention(vocab_size_source, vocab_size_target, embedding_dim, lstm_units)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1780/1780 [==============================] - 208s 107ms/step - loss: 1.2531 - accuracy: 0.7980\n",
      "Epoch 2/10\n",
      "1780/1780 [==============================] - 246s 124ms/step - loss: 0.9572 - accuracy: 0.8238\n",
      "Epoch 3/10\n",
      "1780/1780 [==============================] - 226s 118ms/step - loss: 0.8698 - accuracy: 0.8323\n",
      "Epoch 4/10\n",
      "1780/1780 [==============================] - 230s 121ms/step - loss: 0.8019 - accuracy: 0.8413\n",
      "Epoch 5/10\n",
      "1780/1780 [==============================] - 231s 121ms/step - loss: 0.7312 - accuracy: 0.8532\n",
      "Epoch 6/10\n",
      "1780/1780 [==============================] - 260s 138ms/step - loss: 0.6723 - accuracy: 0.8635\n",
      "Epoch 7/10\n",
      "1780/1780 [==============================] - 247s 129ms/step - loss: 0.6311 - accuracy: 0.8706\n",
      "Epoch 8/10\n",
      "1780/1780 [==============================] - 240s 127ms/step - loss: 0.6018 - accuracy: 0.8752\n",
      "Epoch 9/10\n",
      "1780/1780 [==============================] - 243s 128ms/step - loss: 0.5801 - accuracy: 0.8787\n",
      "Epoch 10/10\n",
      "1780/1780 [==============================] - 242s 128ms/step - loss: 0.5637 - accuracy: 0.8813\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data_gen, epochs = 1, steps_per_epoch=len(data_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'generators' has no attribute 'translate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Guillermo\\Desktop\\My_projects\\English Spanish NLP\\implementation.ipynb Cell 5\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guillermo/Desktop/My_projects/English%20Spanish%20NLP/implementation.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m english_sentence \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWelcome to the tea party.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Guillermo/Desktop/My_projects/English%20Spanish%20NLP/implementation.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m spanish_sentence \u001b[39m=\u001b[39m gens\u001b[39m.\u001b[39;49mtranslate(model, english_sentence, data_gen)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guillermo/Desktop/My_projects/English%20Spanish%20NLP/implementation.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnglish: \u001b[39m\u001b[39m{\u001b[39;00menglish_sentence\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Guillermo/Desktop/My_projects/English%20Spanish%20NLP/implementation.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSpanish: \u001b[39m\u001b[39m{\u001b[39;00mspanish_sentence\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'generators' has no attribute 'translate'"
     ]
    }
   ],
   "source": [
    "english_sentence = \"Welcome to the tea party.\"\n",
    "spanish_sentence = gens.translate(model, english_sentence, data_gen)\n",
    "print(f\"English: {english_sentence}\")\n",
    "print(f\"Spanish: {spanish_sentence}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
